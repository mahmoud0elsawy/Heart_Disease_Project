# ğŸ«€ Heart Disease Prediction & Analysis

This project focuses on analyzing and predicting **heart disease risks** using **Machine Learning**.  
The workflow covers data preprocessing, feature selection, dimensionality reduction, supervised learning, clustering, and model deployment.

---

## ğŸ“‚ Project Structure



project/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ heart_disease.csv # Dataset (processed and saved in each step)
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ LogisticRegression.pkl # Saved best supervised model
â”‚ â””â”€â”€ kmeans_model.pkl # Saved clustering model
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_pca.md # Dimensionality reduction with PCA
â”‚ â”œâ”€â”€ 02_feature_selection.md# Feature selection with ANOVA F-test
â”‚ â”œâ”€â”€ 03_classification.md # Classification models (LR, DT, RF, SVM)
â”‚ â”œâ”€â”€ 04_clustering.md # KMeans & Hierarchical clustering
â”‚ â”œâ”€â”€ 05_visualization.md # Data visualization & EDA
â”‚ â””â”€â”€ 06_deployment.md # Model saving & deployment steps
â”‚
â””â”€â”€ README.md # Project documentation


---

## ğŸ”‘ Steps Overview

### 1ï¸âƒ£ PCA (Principal Component Analysis)
- Reduced dimensionality of the dataset.  
- Visualized explained variance and first 2 components.  
- Ensured **95% variance** coverage with ~8 components.  
- Saved transformed dataset.

### 2ï¸âƒ£ Feature Selection
- Applied **ANOVA F-test** with `SelectKBest`.  
- Selected **top 7 features** based on importance scores.  
- Updated dataset with only selected features + target.

### 3ï¸âƒ£ Classification Models
- Compared multiple classifiers:
  - Logistic Regression  
  - Decision Tree  
  - Random Forest  
  - Support Vector Machine  
- Evaluated using **Accuracy, Confusion Matrix, and Classification Report**.  
- **Logistic Regression** performed best and was saved.

### 4ï¸âƒ£ Clustering
- Applied **KMeans** with optimal `k` determined using Elbow Method.  
- Compared **KMeans vs. Hierarchical clustering**.  
- Visualized clusters after PCA (2D reduction).  
- Saved clustering pipeline with scaling.

### 5ï¸âƒ£ Visualization
- Plotted key features, PCA explained variance, feature importance, clustering distributions, etc.  
- Used **Matplotlib** and **Seaborn** for insights.

### 6ï¸âƒ£ Deployment
- Best supervised model saved as:
  - `../models/LogisticRegression.pkl`  
- Clustering model saved as:
  - `../models/kmeans_model.pkl`  
- Ready for loading and prediction in production apps.

---

## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/heart-disease-ml.git
   cd heart-disease-ml


Install dependencies:

pip install -r requirements.txt


Run Jupyter notebooks (or open .md converted versions).

To load saved models:

import joblib

model = joblib.load("models/LogisticRegression.pkl")
prediction = model.predict(new_data)  # new_data must match features

ğŸ“Š Results

Logistic Regression achieved the best accuracy (~X%).

PCA reduced dimensions while keeping 95% variance.

Feature selection identified the most significant attributes for prediction.

Clustering showed meaningful group separation in 2D PCA space.

ğŸ› ï¸ Tools & Libraries

Python, Pandas, NumPy

Scikit-learn

Matplotlib, Seaborn

Joblib